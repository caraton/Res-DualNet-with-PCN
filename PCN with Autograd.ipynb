{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deep-learning-study.tistory.com/534\n",
    "# https://github.com/pytorch/examples/blob/3970e068c7f18d2d54db2afee6ddd81ef3f93c24/imagenet/main.py#L171\n",
    "# https://ai.dreamkkt.com/54\n",
    "# https://github.com/BerenMillidge/PredictiveCodingBackprop\n",
    "# https://github.com/nalonso2/PredictiveCoding-MQSeqIL/tree/main\n",
    "# https://github.com/ptrblck/pytorch_misc/blob/master/batch_norm_manual.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://eehoeskrap.tistory.com/430 : batch normalization\n",
    "# https://jay-chamber.tistory.com/entry/torchTensor%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC : .grad, .is_leaf, retain_graph, requires_grad 등 설명\n",
    "# https://darkpgmr.tistory.com/132 : Jacobian, Hessian 설명\n",
    "# https://math.stackexchange.com/questions/3643354/difference-between-vjp-and-jvp : Vector-Jacobian Product 설명\n",
    "# https://pytorch.org/docs/stable/generated/torch.autograd.functional.vjp.html : Vector-Jacobian Product 설명\n",
    "# https://tutorials.pytorch.kr/intermediate/jacobians_hessians.html\n",
    "\n",
    "# https://codingalone.tistory.com/2 : colab 시 커스텀 모듈 import 하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "# torchvision.datasets 을 이용해 ImageNet 데이터셋을 관리\n",
    "import torchvision.transforms as transforms\n",
    "# MNIST등의 데이터셋에 들어있는 데이터들을 원하는 모양으로 변환할때 사용하는 모듈\n",
    "\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "# from torch import FloatTensor, optim 같이 한줄로 합쳐도 됨 (as로 새이름 정하지 않을경우)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# 학습 진행이 느려지면 자동으로 lr값을 조정해주는 module\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# 미니배치 데이터 로딩을 도울 모듈\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "# n01443537 같이 되어있는 클래스 이름들을 goldfish 와 같이 쉽게 바꿔줄 때 사용할 파일이 JSON파일\n",
    "import os\n",
    "# os.path.join(save_path, filename) 으로 파일 경로 합칠 때 사용\n",
    "import shutil\n",
    "# shutil.copyfile(path_a, path_b) a 경로의 파일을 b 경로에 복사\n",
    "\n",
    "import scipy\n",
    "\n",
    "\n",
    "import torchsummary\n",
    "# 모델 구조 표로 정리해서 보여주는 모듈\n",
    "# torchsummary.summary(model, input_size=(3, 224, 224), batch_size=64) 와 같이 사용\n",
    "\n",
    "from torchvision import models\n",
    "# pretrained 된 모델들을 담고 있는 모듈\n",
    "\n",
    "import torchvision.transforms.functional as visionF\n",
    "# 이미지 표시에 쓰이는 visionF.to_pil_image(img) 함수등 여러 함수 포함\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "# 이미지들을 표시할 grid 생성\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "# 시간 측정에 사용\n",
    "\n",
    "import math\n",
    "\n",
    "import copy\n",
    "# copy.deepcopy()로 깊은 복사 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PCfunctions import *\n",
    "\n",
    "from PClayers import *\n",
    "from PClayersAG import *\n",
    "\n",
    "from PCNetAG import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() \n",
    "# GPU 사용가능하면 True 반환\n",
    "\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(f\"==>> device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.247, 0.243, 0.262]),\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.247, 0.243, 0.262]),\n",
    "])\n",
    "\n",
    "# normalize 값 계산 : https://github.com/kuangliu/pytorch-cifar/issues/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = dsets.CIFAR10(root='../CIFAR10', train=True, download=True, transform=transform)\n",
    "# train_set.data는 (50000, 32, 32, 3)꼴\n",
    "# train_set.targets는 (50000,) 꼴\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_set = dsets.CIFAR10(root='../CIFAR10', train=False, download=True, transform=val_transform)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "# val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "print(len(val_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "def pcnet_AG_256():\n",
    "    return PCNetAG(PCBlockAG, [3,4,6,3], learning_rate=learning_rate, momentum=0.1, device=device, n_iter_dx= 10, num_cnn_output_channel=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pcnet_AG_256()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchsummary.summary(model, (3,32,32), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_state(model=model, load_path='../CIFAR10/data/2023-09-14-09;08;07_epoch_29.pth')\n",
    "\n",
    "\n",
    "# date_load_file = '2023-09-14-09;08;07_history'\n",
    "# load_path = os.path.join(\"../CIFAR10/data/\", f'{date_load_file}.json')\n",
    "# # load_path = '../CIFAR10/data/2023-09-13-12;18;53_history.json'\n",
    "# loss_history, acc_history, time_history, total_num_epochs = load_history(load_path=load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = {'train':[], 'val':[]}\n",
    "acc_history = {'train_top1':[], 'val_top1':[], 'train_top5':[], 'val_top5':[]}\n",
    "time_history = []\n",
    "total_num_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [], 'val': []}\n",
      "{'train_top1': [], 'val_top1': [], 'train_top5': [], 'val_top5': []}\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(loss_history)\n",
    "print(acc_history)\n",
    "print(time_history)\n",
    "print(total_num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_train = {\n",
    "#     \"num_epochs\": 5,\n",
    "#     \"train_loader\": train_loader,\n",
    "#     \"val_loader\": val_loader,\n",
    "#     \"sanity_check\": True,\n",
    "#     # 모델 오류 확인 떄 sanity_check True로 두면 빠르게 확인 가능\n",
    "#     \"save_path\": \"../CIFAR10/data/\",\n",
    "#     \"loss_history\": loss_history,\n",
    "#     \"acc_history\": acc_history,\n",
    "#     \"total_num_epochs\": total_num_epochs,\n",
    "#     \"time_history\": time_history\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    \"num_epochs\": 3,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"sanity_check\": False,\n",
    "    # 모델 오류 확인 떄 sanity_check True로 두면 빠르게 확인 가능\n",
    "    \"save_path\": \"../CIFAR10/data/\",\n",
    "    \"loss_history\": loss_history,\n",
    "    \"acc_history\": acc_history,\n",
    "    \"time_history\": time_history,\n",
    "    \"total_num_epochs\": total_num_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 22:45:19\n",
      "--------------------------------------------------\n",
      "2023-09-29 22:45:19\n",
      "Epoch 0/2, current lr = 0.01\n",
      "==>> len_data: 50000\n",
      "train loss: 2.43651314, train accuracy: (top1: 22.06%, top5: 69.16%)\n",
      "elapsed time: 0:10:37\n",
      "==>> len_data: 10000\n",
      "val loss: 2.74192522, val accuracy: (top1: 21.21%, top5: 72.37%)\n",
      "elapsed time: 0:00:06\n",
      " epoch elapsed time = 0:10:43\n",
      "==>> total_num_epochs: 1\n",
      "--------------------------------------------------\n",
      "2023-09-29 22:56:02\n",
      "Epoch 1/2, current lr = 0.01\n",
      "==>> len_data: 50000\n",
      "train loss: 2.23895458, train accuracy: (top1: 30.66%, top5: 75.29%)\n",
      "elapsed time: 0:10:34\n",
      "==>> len_data: 10000\n",
      "val loss: 2.40382702, val accuracy: (top1: 27.51%, top5: 71.97%)\n",
      "elapsed time: 0:00:06\n",
      " epoch elapsed time = 0:10:41\n",
      "==>> total_num_epochs: 2\n",
      "--------------------------------------------------\n",
      "2023-09-29 23:06:44\n",
      "Epoch 2/2, current lr = 0.01\n",
      "==>> len_data: 50000\n",
      "train loss: 1.96418512, train accuracy: (top1: 44.08%, top5: 79.03%)\n",
      "elapsed time: 0:10:23\n",
      "==>> len_data: 10000\n",
      "val loss: 2.35822803, val accuracy: (top1: 25.86%, top5: 78.67%)\n",
      "elapsed time: 0:00:05\n",
      " epoch elapsed time = 0:10:29\n",
      "==>> total_num_epochs: 3\n"
     ]
    }
   ],
   "source": [
    "# pcnet_AG_256\n",
    "# batch_size 32\n",
    "# BN layer autograd 사용\n",
    "# momentum 0.1\n",
    "\n",
    "\n",
    "trained_model, loss_hist, acc_hist, time_hist, total_num_epochs = train_and_val(model=model, params=params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcnet_AG_256\n",
    "# batch_size 32\n",
    "# BN layer autograd 사용\n",
    "# momentum 0.1\n",
    "\n",
    "\n",
    "# plot loss progress\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1,total_num_epochs+1),loss_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,total_num_epochs+1),loss_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot top1 accuracy progress\n",
    "plt.title(\"Train-Val Top1 Accuracy\")\n",
    "plt.plot(range(1,total_num_epochs+1),acc_hist[\"train_top1\"],label=\"train\")\n",
    "plt.plot(range(1,total_num_epochs+1),acc_hist[\"val_top1\"],label=\"val\")\n",
    "plt.ylabel(\"Top1 Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot top5 accuracy progress\n",
    "plt.title(\"Train-Val Top5 Accuracy\")\n",
    "plt.plot(range(1,total_num_epochs+1),acc_hist[\"train_top5\"],label=\"train\")\n",
    "plt.plot(range(1,total_num_epochs+1),acc_hist[\"val_top5\"],label=\"val\")\n",
    "plt.ylabel(\"Top5 Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> len_data: 50000\n",
      "val loss: 2.35366884, val accuracy: (top1: 25.72%, top5: 78.08%)\n"
     ]
    }
   ],
   "source": [
    "# pcnet_AG_256\n",
    "# batch_size 32\n",
    "# BN layer autograd 사용\n",
    "# momentum 0.1\n",
    "\n",
    "# train 셋으로 정확도 검증해보기\n",
    "model.eval()\n",
    "for block in model.conv2_x.blocks:\n",
    "    block.eval()\n",
    "for block in model.conv3_x.blocks:\n",
    "    block.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc1, val_acc5 = loss_epoch(\n",
    "        model=model,\n",
    "        data_loader=train_loader,\n",
    "        sanity_check=False,\n",
    "        is_training=False,\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"val loss: {val_loss:>.9}, val accuracy: (top1: {val_acc1:3.2f}%, top5: {val_acc5:3.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> len_data: 50000\n",
      "val loss: 2.37822019, val accuracy: (top1: 25.66%, top5: 77.76%)\n"
     ]
    }
   ],
   "source": [
    "# pcnet_AG_256\n",
    "# batch_size 32\n",
    "# BN layer autograd 사용\n",
    "# momentum 0.1\n",
    "\n",
    "\n",
    "# train 셋으로 정확도 검증해보기\n",
    "model.train()\n",
    "for block in model.conv2_x.blocks:\n",
    "    block.train()\n",
    "for block in model.conv3_x.blocks:\n",
    "    block.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc1, val_acc5 = loss_epoch(\n",
    "        model=model,\n",
    "        data_loader=train_loader,\n",
    "        sanity_check=False,\n",
    "        is_training=False,\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"val loss: {val_loss:>.9}, val accuracy: (top1: {val_acc1:3.2f}%, top5: {val_acc5:3.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
